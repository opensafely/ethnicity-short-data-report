{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import file\n",
    "input_path = 'C:/Users/candrews/Documents/GitHub/ethnicity-short-data-report/output/data/input.feather'\n",
    "\n",
    "# Definition\n",
    "definitions = ['ethnicity_5', 'ethnicity_new_5', 'ethnicity_primis_5']\n",
    "\n",
    "# Code dictionary\n",
    "code_dict = {\n",
    "    'imd': {0: 'Unknown', 1: '1 Most deprived', 2: '2', 3: '3', 4: '4', 5: '5 Least deprived'},\n",
    "    'ethnicity_5': {1:'White', 2:'Mixed', 3:'Asian', 4:'Black', 5:'Other'},\n",
    "    'ethnicity_new_5': {1:'White', 2:'Mixed', 3:'Asian', 4:'Black', 5:'Other'},\n",
    "    'ethnicity_primis_5': {1:'White', 2:'Mixed', 3:'Asian', 4:'Black', 5:'Other'},\n",
    "}\n",
    "\n",
    "# Other variables to include\n",
    "other_vars = ['white','mixed','asian','black','other']\n",
    "other_vars_combined = [x+'_'+y for x in definitions for y in other_vars]\n",
    "\n",
    "# Dates\n",
    "dates = False\n",
    "date_min = ''\n",
    "date_max = ''\n",
    "time_delta = ''\n",
    "\n",
    "# Min/max range\n",
    "min_range = 4\n",
    "max_range = 200\n",
    "\n",
    "# Null value – could be multiple values in a list [0,'0',NA]\n",
    "null = [0,\"0\"]\n",
    "\n",
    "# Covariates\n",
    "demographic_covariates = ['age_band', 'sex', 'region', 'imd']\n",
    "clinical_covariates = ['dementia', 'diabetes', 'hypertension', 'learning_disability']\n",
    "\n",
    "# Output filepath\n",
    "output_path = 'phenotype_validation_ethnicity/5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import itertools\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "#from ebmdatalab import charts\n",
    "from functools import reduce\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def redact_round_table(df_in):\n",
    "    \"\"\"Redacts counts <= 5 and rounds counts to nearest 5\"\"\"\n",
    "    df_out = df_in.where(df_in > 5, np.nan).apply(lambda x: 5 * round(x/5))\n",
    "    return df_out\n",
    "\n",
    "def import_clean(input_path, definitions, other_vars, demographic_covariates, \n",
    "                 clinical_covariates, null, date_min, date_max, \n",
    "                 time_delta, output_path, code_dict='', dates=False):\n",
    "    # Import\n",
    "    df_import = pd.read_feather(input_path)\n",
    "    # Dates\n",
    "    if dates==True:\n",
    "        date_vars = [definition+'_date' for definition in definitions]\n",
    "        # Create variable that captures difference in measurement dates\n",
    "        date_diff_vars = []\n",
    "        # Define start and end dates\n",
    "        start_date = datetime.datetime.strptime(date_min, '%Y-%m-%d')\n",
    "        end_date = datetime.datetime.strptime(date_max, '%Y-%m-%d')\n",
    "        for definition in definitions:\n",
    "            # Remove OpenSAFELY null dates \n",
    "            df_import.loc[df_import[definition+'_date'] == '1900-01-01', definition+'_date'] = np.nan\n",
    "            # Limit to period of interest             \n",
    "            df_import[definition+'_date'] = pd.to_datetime(df_import[definition+'_date'])\n",
    "            df_import.loc[df_import[definition+'_date'] < start_date, definition+'_date'] = np.nan\n",
    "            df_import.loc[df_import[definition+'_date'] > end_date, definition+'_date'] = np.nan\n",
    "            # Remove the measurement if outside the date parameters\n",
    "            df_import.loc[df_import[definition+'_date'].isna(), definition] = np.nan\n",
    "            df_import \n",
    "            # Create difference between measurement dates\n",
    "            df_import[definition+'_date'] = df_import[definition+'_date'].dt.to_period(time_delta).dt.to_timestamp()\n",
    "            df_import = df_import.sort_values(by=['patient_id',definition+'_date'])\n",
    "            df_import['date_diff_' + definition] = round(df_import.groupby('patient_id')[definition+'_date'].diff() / np.timedelta64(1, time_delta))\n",
    "            date_diff_vars.append('date_diff_' + definition)\n",
    "    else: \n",
    "        date_vars = []\n",
    "        date_diff_vars = []\n",
    "    # Codes\n",
    "    if code_dict!='':\n",
    "        for key in code_dict:\n",
    "            df_import[key] = df_import[key].astype(float)\n",
    "            df_import[key] = df_import[key].replace(code_dict[key])\n",
    "    # Subset to relevant columns\n",
    "    df_clean = df_import[['patient_id'] + definitions + other_vars + date_vars + date_diff_vars + demographic_covariates + clinical_covariates]\n",
    "    # Limit to relevant date range\n",
    "    df_clean = df_clean.sort_values(by='patient_id').reset_index(drop=True)\n",
    "    # Set null values to nan\n",
    "    for definition in definitions: \n",
    "        df_clean.loc[df_clean[definition].isin(null), definition] = np.nan\n",
    "     # Create order for categorical variables\n",
    "    for group in demographic_covariates + clinical_covariates:\n",
    "        if df_clean[group].dtype.name == 'category':\n",
    "            li_order = sorted(df_clean[group].dropna().unique().tolist())\n",
    "            df_clean[group] = df_clean[group].cat.reorder_categories(li_order, ordered=True)\n",
    "    # Mark patients with value filled/missing for each definition\n",
    "    li_filled = []\n",
    "    for definition in definitions:\n",
    "        df_fill = pd.DataFrame(df_clean.groupby(\"patient_id\")[definition].any().astype('int')).rename(\n",
    "            columns={definition:definition+'_filled'}\n",
    "        )\n",
    "        df_fill[definition+'_missing'] = 1-df_fill[definition+'_filled']\n",
    "        li_filled.append(df_fill)\n",
    "\n",
    "    df_filled = pd.concat(li_filled, axis=1)\n",
    "    # Remove list from memory\n",
    "    del li_filled  \n",
    "    df_clean = df_clean.merge(df_filled, on='patient_id')\n",
    "    \n",
    "    # Flag all filled/all missing\n",
    "    li_col_filled = [col for col in df_clean.columns if col.endswith('_filled')]\n",
    "    li_col_missing = [col for col in df_clean.columns if col.endswith('_missing')]\n",
    "    df_clean['all_filled'] = (df_clean[li_col_filled].sum(axis=1) == len(definitions)).astype(int)\n",
    "    df_clean['all_missing'] = (df_clean[li_col_missing].sum(axis=1) == len(definitions)).astype(int)\n",
    "    \n",
    "    # Check whether output paths exist or not, create if missing\n",
    "    path_tables = f'output/{output_path}/tables'\n",
    "    path_figures = f'output/{output_path}/figures'\n",
    "    li_filepaths = [path_tables, path_figures]\n",
    "\n",
    "    for filepath in li_filepaths:\n",
    "        exists = os.path.exists(filepath)\n",
    "        if not exists:\n",
    "            os.makedirs(filepath)\n",
    "\n",
    "    return df_clean\n",
    "\n",
    "def patient_counts(df_clean, definitions, demographic_covariates, clinical_covariates, output_path, categories=False, missing=False):\n",
    "    suffix = '_filled'\n",
    "    subgroup = 'with records'\n",
    "    overlap = 'all_filled'\n",
    "    if missing == True:\n",
    "        suffix = '_missing'\n",
    "        subgroup = 'missing records'\n",
    "        overlap = 'all_missing'\n",
    "    if categories == True:\n",
    "        li_cat_def = []\n",
    "        li_cat = df_clean[definitions[0]].dropna().astype(str).sort_values().unique().tolist()\n",
    "        for x in li_cat:\n",
    "            for definition in definitions:\n",
    "                df_clean.loc[df_clean[definition] == x, f'{definition}_{x}_filled'] = 1 \n",
    "                li_cat_def.append(f'{definition}_{x}')\n",
    "        definitions = li_cat_def\n",
    "\n",
    "    # All with measurement\n",
    "    li_filled = []\n",
    "    for definition in definitions:\n",
    "        df_temp = df_clean[['patient_id', definition+suffix]].drop_duplicates().dropna().set_index('patient_id')\n",
    "        li_filled.append(df_temp)\n",
    "\n",
    "    df_temp = df_clean[['patient_id', overlap]].drop_duplicates().dropna().set_index('patient_id')\n",
    "    li_filled.append(df_temp)\n",
    "    \n",
    "    df_temp2 = pd.concat(li_filled, axis=1)\n",
    "    df_temp2['population'] = 1\n",
    "    # Remove list from memory\n",
    "    del li_filled\n",
    "    df_all = pd.DataFrame(df_temp2.sum()).T\n",
    "    df_all['group'],df_all['subgroup'] = ['all',subgroup]\n",
    "    df_all = df_all.set_index(['group','subgroup'])\n",
    "    \n",
    "    # By group\n",
    "    li_group = []\n",
    "    for group in demographic_covariates + clinical_covariates:\n",
    "        li_filled_group = []\n",
    "        for definition in definitions:\n",
    "            df_temp = df_clean[['patient_id', definition+suffix, group]].drop_duplicates().dropna().reset_index(drop=True)\n",
    "            li_filled_group.append(df_temp)\n",
    "            \n",
    "        df_temp = df_clean[['patient_id', overlap, group]].drop_duplicates().dropna().reset_index(drop=True)\n",
    "        li_filled_group.append(df_temp)\n",
    "        \n",
    "        df_reduce = reduce(lambda df1, df2: pd.merge(df1, df2,on=['patient_id',group],how='outer'), li_filled_group)\n",
    "        df_reduce['population'] = 1\n",
    "        # Remove list from memory\n",
    "        del li_filled_group \n",
    "        df_reduce2 = df_reduce.sort_values(by=group).drop(columns=['patient_id']).groupby(group).sum().reset_index()\n",
    "        df_reduce2['group'] = group\n",
    "        df_reduce2 = df_reduce2.rename(columns={group:'subgroup'})\n",
    "        li_group.append(df_reduce2)\n",
    "    df_all_group = pd.concat(li_group, axis=0, ignore_index=True).set_index(['group','subgroup'])\n",
    "    # Remove list from memory\n",
    "    del li_group \n",
    "    \n",
    "    # Redact\n",
    "    df_append = redact_round_table(df_all.append(df_all_group))\n",
    "        \n",
    "    # Create percentage columns \n",
    "    for definition in definitions:\n",
    "        df_append[definition+'_pct'] = round((df_append[definition+suffix].div(df_append['population']))*100,1)\n",
    "    df_append[overlap+'_pct'] = round((df_append[overlap].div(df_append['population']))*100,1)\n",
    "\n",
    "    # Final redaction step\n",
    "    df_append = df_append.where(~df_append.isna(), '-')  \n",
    "\n",
    "    # Combine count and percentage columns\n",
    "    for definition in definitions:\n",
    "        df_append[definition] = df_append[definition+suffix].astype(str) + \" (\" + df_append[definition+'_pct'].astype(str) + \")\" \n",
    "        df_append = df_append.drop(columns=[definition+suffix,definition+'_pct'])\n",
    "    df_append[overlap] = df_append[overlap].astype(str) + \" (\" + df_append[overlap+'_pct'].astype(str) + \")\" \n",
    "    df_append = df_append.drop(columns=[overlap+'_pct'])\n",
    "    \n",
    "    # Column order\n",
    "    li_col_order = []\n",
    "    for definition in definitions:\n",
    "        li_col_order.append(definition)\n",
    "    li_col_order.append(overlap)\n",
    "    li_col_order.append('population')\n",
    "\n",
    "    df_all_redact = df_append[li_col_order]\n",
    "\n",
    "    if categories == False:\n",
    "        df_all_redact.to_csv(f'output/{output_path}/tables/patient_counts{suffix}.csv')\n",
    "    if categories == True:\n",
    "        df_all_redact.to_csv(f'output/{output_path}/tables/patient_counts_by_categories{suffix}.csv')\n",
    "\n",
    "def display_heatmap(df_clean, definitions, output_path):\n",
    "    # All with measurement\n",
    "    li_filled = []\n",
    "    for definition in definitions:\n",
    "        df_temp = df_clean[['patient_id']].drop_duplicates().set_index('patient_id')\n",
    "        df_temp[definition+'_filled'] = 1\n",
    "        df_temp = df_clean[['patient_id', definition+'_filled']].drop_duplicates().dropna().set_index('patient_id')\n",
    "        li_filled.append(df_temp)\n",
    "\n",
    "    # Prepare data for heatmap input\n",
    "    df_temp2 = pd.concat(li_filled, axis=1)\n",
    "    # Remove list from memory\n",
    "    del li_filled \n",
    "    df_transform = df_temp2.replace(np.nan,0)\n",
    "    df_dot = redact_round_table(df_transform.T.dot(df_transform))\n",
    "    \n",
    "    # Create mask to eliminate duplicates in heatmap\n",
    "    mask = np.triu(np.ones_like(df_dot))\n",
    "    np.fill_diagonal(mask[::1], 0)\n",
    "\n",
    "    # Draw the heatmap with the mask\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    sns.heatmap(df_dot, annot=True, mask=mask, fmt='g', cmap=\"YlGnBu\", vmin=0)\n",
    "    #plt.show()\n",
    "    plt.savefig(f'output/{output_path}/figures/heatmap.png')\n",
    "\n",
    "def records_over_time(df_clean, definitions, demographic_covariates, clinical_covariates, output_path):\n",
    "    li_df = []\n",
    "    for definition in definitions:\n",
    "        df_grouped = df_clean[[definition+'_date',definition]].groupby(definition+'_date').count().reset_index().rename(columns={definition+'_date':'date'}).set_index('date')\n",
    "        li_df.append(redact_round_table(df_grouped))\n",
    "    df_all_time = pd.concat(li_df).stack().reset_index().rename(columns={'level_1':'variable',0:'value'})\n",
    "    # Remove list from memory\n",
    "    del li_df \n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    fig.autofmt_xdate()\n",
    "    sns.lineplot(x = 'date', y = 'value', hue='variable', data = df_all_time, ax=ax).set_title('New records by month')\n",
    "    ax.legend().set_title('')\n",
    "    plt.savefig(f'output/{output_path}/figures/records_over_time.png')\n",
    "\n",
    "    for group in demographic_covariates + clinical_covariates:\n",
    "        for definition in definitions:\n",
    "            df_grouped = df_clean[[definition+'_date',definition,group]].groupby(\n",
    "                                  [definition+'_date',group]).count().reset_index().rename(columns={definition+'_date':'date'}).set_index(['date', group])\n",
    "            df_time=redact_round_table(df_grouped).reset_index()\n",
    "            fig, ax = plt.subplots(figsize=(12, 8))\n",
    "            fig.autofmt_xdate()\n",
    "            sns.lineplot(x = 'date', y = definition, hue=group, data = df_time, ax=ax).set_title(f'{definition} recorded by {group} and month')\n",
    "            ax.legend().set_title('')\n",
    "            plt.savefig(f'output/{output_path}/figures/records_over_time_{definition}_{group}.png')\n",
    "            \n",
    "def report_distribution(df_occ, definitions, num_definitions, output_path, group=''):\n",
    "    \"\"\"\n",
    "    Plots histogram or boxplots of distribution\n",
    "    \"\"\"\n",
    "    if group == '':\n",
    "        if num_definitions == 1:\n",
    "            for definition in definitions: \n",
    "\n",
    "                avg_value = pd.DataFrame(\n",
    "                    df_occ[definition].agg(\n",
    "                        ['mean','count']\n",
    "                    )\n",
    "                )\n",
    "                if avg_value.loc['count'][0] > 6:\n",
    "                    avg_value.loc['count'][0] = 5 * round(avg_value.loc['count'][0]/5)\n",
    "                    print(f'Average {definition}:\\n')\n",
    "                    #display(avg_value)\n",
    "                    avg_value.to_csv(f'output/{output_path}/tables/avg_value_{definition}.csv')\n",
    "                    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "                    hist_data = df_occ[definition].loc[~df_occ[definition].isna()]\n",
    "                    plt.hist(hist_data, bins=np.arange(min(hist_data), max(hist_data)))\n",
    "                    plt.title('Distribution of ' + definition)\n",
    "                    #plt.show()\n",
    "                    plt.savefig(f'output/{output_path}/figures/distribution.png')\n",
    "                else:\n",
    "                    print('Table and plot redacted due to low counts.')\n",
    "                    \n",
    "        else:\n",
    "            df_bp = df_occ[definitions]\n",
    "            avg = pd.DataFrame(df_bp.mean(),columns=['mean'])\n",
    "            ct = pd.DataFrame(df_bp.count(),columns=['count'])\n",
    "            avg_value = avg.merge(ct, left_index=True, right_index=True)\n",
    "            # Redact and round values\n",
    "            avg_value['count'] = avg_value['count'].where(\n",
    "                avg_value['count'] > 5, np.nan).apply(lambda x: 5 * round(x/5) if ~np.isnan(x) else x)\n",
    "            print('Averages:\\n')\n",
    "            #display(avg_value)\n",
    "            avg_value.to_csv(f'output/{output_path}/tables/avg_value.csv')\n",
    "            fig, ax = plt.subplots(figsize=(12, 8))\n",
    "            sns.boxplot(data=df_bp,showfliers = False)\n",
    "            plt.title(\"Distributions of values\")\n",
    "            #plt.show()\n",
    "            plt.savefig(f'output/{output_path}/figures/distribution.png')\n",
    "    else:\n",
    "        if num_definitions == 1:\n",
    "            for definition in definitions: \n",
    "                df_bp = df_occ[[group]+ [definition]]\n",
    "                avg_value = df_bp.groupby(group)[definition].agg(\n",
    "                    ['mean', 'count']\n",
    "                )\n",
    "                # Redact and round values\n",
    "                avg_value['count'] = avg_value['count'].where(\n",
    "                    avg_value['count'] > 5, np.nan).apply(lambda x: 5 * round(x/5) if ~np.isnan(x) else x)\n",
    "                avg_value.loc[avg_value['count'].isna(), ['count','mean']] = ['-','-']\n",
    "                print(f'Averages by {group}:\\n')\n",
    "                #display(avg_value)    \n",
    "                avg_value.to_csv(f'output/{output_path}/tables/avg_value_{definition}_{group}.csv')\n",
    "                null_index = avg_value[avg_value['count'] == '-'].index.tolist()\n",
    "                fig, ax = plt.subplots(figsize=(12, 8))\n",
    "                sns.boxplot(x=group, y=definition, data=df_bp.loc[~df_bp[group].isin(null_index)], showfliers=False)\n",
    "                plt.title(f\"Distributions by {group}\")\n",
    "                #plt.show()\n",
    "                plt.savefig(f'output/{output_path}/figures/distribution_{group}.png')\n",
    "        else:\n",
    "            if df_occ[group].dtype == 'bool':\n",
    "                df_occ[group] = df_occ[group].apply(lambda x: str(x))\n",
    "            df_occ = df_occ.loc[~df_occ[group].isna()] # Drop nan categories\n",
    "            df_bp = df_occ[[group] + definitions]\n",
    "            avg = df_bp.groupby(group).mean().add_prefix(\"avg_\")\n",
    "            ct = df_bp.groupby(group).count().add_prefix(\"ct_\")\n",
    "            avg_value = avg.merge(ct, left_on=group, right_on=group)\n",
    "            for definition in definitions:\n",
    "                # Redact and round values\n",
    "                avg_value['ct_'+definition] = avg_value['ct_'+definition].where(\n",
    "                    avg_value['ct_'+definition] > 5, np.nan).apply(lambda x: 5 * round(x/5) if ~np.isnan(x) else x)\n",
    "                avg_value.loc[avg_value['ct_'+definition].isna(), \n",
    "                                    ['ct_'+definition,'avg_'+definition]] = ['-','-']\n",
    "            print(f'Averages by {group}:\\n')\n",
    "            #display(avg_value)\n",
    "            avg_value.to_csv(f'output/{output_path}/tables/avg_value_{group}.csv')\n",
    "            for definition in definitions:\n",
    "                null_index = []\n",
    "                null_index = avg_value[avg_value['ct_'+definition] == '-'].index.tolist()\n",
    "                df_bp.loc[df_bp[group].isin(null_index),definition] = np.nan\n",
    "            fig, ax = plt.subplots(figsize=(12, 8))\n",
    "            df_plot = df_bp.melt(id_vars=group, value_vars=definitions)\n",
    "            sns.boxplot(x=group, y='value', hue='variable', data=df_plot, showfliers=False)\n",
    "            plt.title(f'Distributions by {group}')\n",
    "            #plt.show()\n",
    "            plt.savefig(f'output/{output_path}/figures/distribution_{group}.png')\n",
    "            \n",
    "def report_out_of_range(df_occ, definitions, min_range, max_range, num_definitions, null, output_path, group=''):\n",
    "    \"\"\"\n",
    "    Reports number of measurements outside of defined range\n",
    "    \"\"\"\n",
    "    \n",
    "    def q25(x):\n",
    "        return x.quantile(0.25)\n",
    "    def q75(x):\n",
    "        return x.quantile(0.75)\n",
    "    \n",
    "    li_dfs = []\n",
    "    \n",
    "    df_oor = df_occ\n",
    "    for definition in definitions: \n",
    "        df_oor.loc[(df_oor[definition] < min_range) | (df_oor[definition] > max_range), \"out_of_range_\"+definition] = 1\n",
    "        # Make definitions null if not out of range or empty\n",
    "        df_oor[\"oor_\" + definition] = df_oor[definition]\n",
    "        df_oor.loc[(df_oor[\"out_of_range_\"+definition] != 1) | (df_oor[definition].isin(null)), \"oor_\" + definition] = np.nan\n",
    "        if group == '':\n",
    "            try:\n",
    "                df_out = df_oor.agg(\n",
    "                                    count = (\"oor_\" + definition, 'count'),\n",
    "                                    mean  = (\"oor_\" + definition, 'mean'),\n",
    "                                    pct25 = (\"oor_\" + definition,q25),\n",
    "                                    pct75 = (\"oor_\" + definition,q75),\n",
    "                                    )\n",
    "            except:\n",
    "                df_out = pd.DataFrame([['count', 0],['mean',np.nan],\n",
    "                                       ['pct25',np.nan],['pct75',np.nan]], \n",
    "                                      columns=['index',\"oor_\" + definition]).set_index('index')\n",
    "            if df_out.loc['count'][\"oor_\" + definition] > 6:\n",
    "                df_out.loc['count'][\"oor_\" + definition] = 5 * round(df_out.loc['count'][\"oor_\" + definition]/5)\n",
    "            else:\n",
    "                df_out[\"oor_\" + definition] = '-'\n",
    "        else:\n",
    "            df_out = df_oor.groupby(group)[\"oor_\" + definition].agg(\n",
    "                                                [('count', 'count'),\n",
    "                                                 ('mean', 'mean'),\n",
    "                                                 ('pct25', q25),\n",
    "                                                 ('pct75', q75)]\n",
    "                                              ).add_suffix(\"_\"+definition)\n",
    "            df_out.loc[df_out[\"count_\" + definition] > 5, \"count_\" + definition] = 5 * round(df_out[\"count_\" + definition]/5)\n",
    "            df_out.loc[df_out[\"count_\" + definition] < 6, \n",
    "                       [\"count_\" + definition, \"mean_\" + definition,\n",
    "                       \"pct25_\" + definition, \"pct75_\" + definition]] = ['-','-','-','-']\n",
    "        li_dfs.append(df_out)    \n",
    "    \n",
    "    if num_definitions == 1:    \n",
    "        #display(df_out)\n",
    "        df_out.to_csv(f'output/{output_path}/tables/out_of_range.csv')\n",
    "        # Remove list from memory\n",
    "        del li_dfs \n",
    "        if group == '': \n",
    "            if df_out[\"oor_\" + definition]['count'] != '-':\n",
    "                df_plot = df_oor[\"oor_\" + definition]\n",
    "                fig, ax = plt.subplots(figsize=(12, 8))\n",
    "                plt.hist(df_plot)\n",
    "                plt.title('Distribution of out of range ' + definition)\n",
    "                #plt.show()\n",
    "                plt.savefig(f'output/{output_path}/figures/out_of_range.png')\n",
    "            else:\n",
    "                print('Plot redacted due to low counts.')\n",
    "        else:\n",
    "            df_oor = df_oor.loc[~df_oor[group].isna()]\n",
    "            for definition in definitions: \n",
    "                null_index = df_out[df_out['count_'+definition] == '-'].index.tolist()\n",
    "                df_oor.loc[df_oor[group].isin(null_index),'oor_'+definition] = np.nan\n",
    "                df_bp = df_oor[[group]+ [\"oor_\" + definition]]\n",
    "                if df_bp[\"oor_\" + definition].sum() > 0:\n",
    "                    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "                    sns.boxplot(x=group, y=\"oor_\" + definition, data=df_bp, showfliers=False)\n",
    "                    plt.title(f\"Distribution of out of range values by {group}\")\n",
    "                    plt.show()\n",
    "                    plt.savefig(f'output/{output_path}/figures/out_of_range_{group}.png')\n",
    "                else:\n",
    "                    print('Plot redacted due to low counts.')\n",
    "    else:\n",
    "        df_merged = reduce(lambda left,right: pd.merge(left,right,left_index=True, right_index=True), li_dfs)\n",
    "        # Remove list from memory\n",
    "        del li_dfs \n",
    "        #display(df_merged)\n",
    "        if group == '':    \n",
    "            df_merged.to_csv(f'output/{output_path}/tables/out_of_range.csv')\n",
    "            cols = [\"oor_\" + definition for definition in definitions]\n",
    "            df_bp = df_oor[cols]\n",
    "            if df_merged[\"oor_\" + definition]['count'] == '-':\n",
    "                df_bp[\"oor_\" + definition] = np.nan\n",
    "            try:\n",
    "                fig, ax = plt.subplots(figsize=(12, 8))\n",
    "                sns.boxplot(data=df_bp, showfliers=False)\n",
    "                plt.title('Distribution of out of range values')\n",
    "                #plt.show()\n",
    "                plt.savefig(f'output/{output_path}/figures/out_of_range.png')\n",
    "            except: \n",
    "                print('Plot redacted due to low counts.')\n",
    "        else:\n",
    "            df_merged.to_csv(f'output/{output_path}/tables/out_of_range_{group}.csv')\n",
    "            df_oor = df_oor.loc[~df_oor[group].isna()]\n",
    "            for definition in definitions: \n",
    "                null_index = df_merged[df_merged['count_'+definition] == '-'].index.tolist()\n",
    "                df_oor.loc[df_oor[group].isin(null_index),'oor_'+definition] = np.nan\n",
    "            if df_oor[group].dtype == 'bool':\n",
    "                df_oor[group] = df_oor[group].apply(lambda x: str(x))\n",
    "            cols = [\"oor_\" + definition for definition in definitions]\n",
    "            df_bp = df_oor[[group] + cols]\n",
    "            df_plot = df_bp.melt(id_vars=group, value_vars=cols)\n",
    "            if df_plot['value'].sum() > 0:\n",
    "                fig, ax = plt.subplots(figsize=(12, 8))\n",
    "                sns.boxplot(x=group, y='value', hue='variable', data=df_plot, showfliers=False)\n",
    "                plt.title(f'Distribution of out of range values by {group}')\n",
    "                #plt.show()\n",
    "                plt.savefig(f'output/{output_path}/figures/out_of_range_{group}.png')\n",
    "            else: \n",
    "                print('Plot redacted due to low counts.')\n",
    "        \n",
    "def report_update_frequency(df_occ, definitions, time_delta, num_definitions, output_path, group=''):\n",
    "    \"\"\"\n",
    "    Plots histogram or boxplot of update frequency and reports average update frequency\n",
    "    \"\"\"\n",
    "    if group == '':\n",
    "        if num_definitions == 1:\n",
    "            for definition in definitions: \n",
    "                avg_update_freq = df_occ.agg(\n",
    "                    avg_diff = (f'date_diff_{definition}', 'mean'),\n",
    "                    count = (f'date_diff_{definition}' , 'count')\n",
    "                )\n",
    "                if avg_update_freq.loc['count'][0] > 6:\n",
    "                    avg_update_freq.loc['count'][0] = 5 * round(avg_update_freq.loc['count'][0]/5)\n",
    "                    print(f'Average update frequency of {definition} by {time_delta}:\\n')\n",
    "                    #display(avg_update_freq)\n",
    "                    avg_update_freq.to_csv(f'output/{output_path}/tables/avg_update_frequency_{definition}.csv')\n",
    "                    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "                    plt.hist(df_occ['date_diff_' + definition])\n",
    "                    plt.title('Update frequency of ' + definition + f\" by {time_delta}\")\n",
    "                    #plt.show()\n",
    "                    plt.savefig(f'output/{output_path}/figures/avg_update_frequency_{definition}.png')\n",
    "                else:\n",
    "                    print('Table and plot redacted due to low counts.')\n",
    "        else:\n",
    "            cols = ['date_diff_' + x for x in definitions]\n",
    "            df_bp = df_occ[cols]\n",
    "            avg_update = pd.DataFrame(df_bp.mean(),columns=['avg_diff'])\n",
    "            ct_update = pd.DataFrame(df_bp.count(),columns=['count'])\n",
    "            avg_update_freq = avg_update.merge(ct_update, left_index=True, right_index=True)\n",
    "            # Redact and round values\n",
    "            avg_update_freq['count'] = avg_update_freq['count'].where(\n",
    "                avg_update_freq['count'] > 5, np.nan).apply(lambda x: 5 * round(x/5) if ~np.isnan(x) else x)\n",
    "            print(f'Average update frequency by {time_delta}:\\n')\n",
    "            #display(avg_update_freq)    \n",
    "            avg_update_freq.to_csv(f'output/{output_path}/tables/avg_update_frequency.csv')\n",
    "            fig, ax = plt.subplots(figsize=(12, 8))\n",
    "            null_index = avg_update_freq[avg_update_freq['count'] == '-'].index.tolist()\n",
    "            sns.boxplot(data=df_bp.drop(columns=null_index), showfliers=False)\n",
    "            plt.title(f\"Update frequency by {time_delta}\")\n",
    "            #plt.show()\n",
    "            plt.savefig(f'output/{output_path}/figures/avg_update_frequency.png')\n",
    "          \n",
    "    else:\n",
    "        if num_definitions == 1:\n",
    "            for definition in definitions: \n",
    "                df_bp = df_occ[[group]+ ['date_diff_' + definition]]\n",
    "                avg_update_freq = df_occ.groupby(group).agg(\n",
    "                    avg_diff = ('date_diff_' + definition, 'mean'),\n",
    "                    count = ('date_diff_' + definition, 'count')\n",
    "                ).reset_index()\n",
    "                # Redact and round values\n",
    "                avg_update_freq['count'] = avg_update_freq['count'].where(\n",
    "                    avg_update_freq['count'] > 5, np.nan).apply(lambda x: 5 * round(x/5) if ~np.isnan(x) else x)\n",
    "                avg_update_freq.loc[avg_update_freq['count'].isna(), ['count','avg_diff']] = ['-','-']\n",
    "                print(f'Average update frequency by {group} and {time_delta}:\\n')\n",
    "                #display(avg_update_freq)    \n",
    "                avg_update_freq.to_csv(f'output/{output_path}/tables/avg_update_frequency_{definition}.csv')\n",
    "                null_index = avg_update_freq[avg_update_freq['count'] == '-'].index.tolist()\n",
    "                fig, ax = plt.subplots(figsize=(12, 8))\n",
    "                sns.boxplot(x=group, y='date_diff_'+definition, data=df_bp.loc[~df_bp[group].isin(null_index)].sort_index(), showfliers=False)\n",
    "                plt.title(f\"Update frequency by {group} and {time_delta}\")\n",
    "                #plt.show()\n",
    "                plt.savefig(f'output/{output_path}/figures/avg_update_frequency_{definition}.png')\n",
    "        else:\n",
    "            if df_occ[group].dtype == 'bool':\n",
    "                df_occ[group] = df_occ[group].apply(lambda x: str(x))\n",
    "            df_occ = df_occ.loc[~df_occ[group].isna()] # Drop nan categories\n",
    "            cols = ['date_diff_' + x for x in definitions]\n",
    "            df_sub = df_occ[[group] + cols]\n",
    "            avg_update = df_sub.groupby(group).mean().add_prefix(\"avg_\")\n",
    "            ct_update = df_sub.groupby(group).count().add_prefix(\"ct_\")\n",
    "            avg_update_freq = avg_update.merge(ct_update, left_on=group, right_on=group).sort_index()\n",
    "            for definition in definitions:\n",
    "                # Redact and round values\n",
    "                avg_update_freq['ct_date_diff_'+definition] = avg_update_freq['ct_date_diff_'+definition].where(\n",
    "                    avg_update_freq['ct_date_diff_'+definition] > 5, np.nan).apply(lambda x: 5 * round(x/5) if ~np.isnan(x) else x)\n",
    "                avg_update_freq.loc[avg_update_freq['ct_date_diff_'+definition].isna(), \n",
    "                                    ['ct_date_diff_'+definition,'avg_date_diff_'+definition]] = ['-','-']\n",
    "            # Sort by index\n",
    "            print(f'Average update frequencies by {time_delta}:\\n')\n",
    "            #display(avg_update_freq)\n",
    "            avg_update_freq.to_csv(f'output/{output_path}/tables/avg_update_frequency_{group}.csv')\n",
    "            for definition in definitions:\n",
    "                null_index = []\n",
    "                null_index = avg_update_freq[avg_update_freq['ct_date_diff_'+definition] == '-'].index.tolist()\n",
    "                df_sub.loc[df_sub[group].isin(null_index),'date_diff_'+definition] = np.nan\n",
    "            fig, ax = plt.subplots(figsize=(12, 8))\n",
    "            df_plot = df_sub.melt(id_vars=group, value_vars=cols)\n",
    "            sns.boxplot(x=group, y='value', hue='variable', data=df_plot, showfliers=False)\n",
    "            plt.title(f'Update frequencies by {group} and {time_delta}')\n",
    "            #plt.show()\n",
    "            plt.savefig(f'output/{output_path}/figures/avg_update_frequency_{group}.png')\n",
    "            \n",
    "def latest_common_comparison(df_clean, definitions, other_vars, output_path):\n",
    "    for definition in definitions:\n",
    "        vars = [s for s in other_vars if s.startswith(definition)]\n",
    "        df_subset = df_clean.loc[~df_clean[definition].isna()]\n",
    "        df_subset=df_subset[[definition]+vars].set_index(definition)\n",
    "\n",
    "        df_subset2 = df_subset.where(df_subset.eq(df_subset.max(1),axis=0))\n",
    "        df_subset_3 = df_subset2.notnull().astype('int').reset_index()\n",
    "        df_sum = redact_round_table(df_subset_3.groupby(definition).sum())\n",
    "  #      df_sum = df_sum.where(~df_sum.isna(), '-')\n",
    "\n",
    "        df_counts = pd.DataFrame(np.diagonal(df_sum),index=df_sum.index,columns=[f'matching (n={np.diagonal(df_sum).sum()})'])\n",
    "\n",
    "        df_sum2 = df_sum.copy(deep=True)\n",
    "        np.fill_diagonal(df_sum2.values, 0)\n",
    "        df_diag = pd.DataFrame(df_sum2.sum(axis=1), columns=[f'not_matching (n={df_sum2.sum(axis=1).sum()})'])\n",
    "        df_out = df_counts.merge(df_diag,right_index=True,left_index=True)\n",
    "        #display(df_out)\n",
    "        df_out.to_csv(f'output/{output_path}/tables/latest_common_simple_{definition}.csv')\n",
    "\n",
    "        df_sum = redact_round_table(df_subset_3.groupby(definition).sum())     \n",
    "\n",
    "        for col in df_sum.columns:\n",
    "            df_sum = df_sum.rename(columns = {col:f'{col} (n={df_sum[col].sum()})'})\n",
    "        #display(df_sum)\n",
    "        df_sum = df_sum.where(~df_sum.isna(), '-')\n",
    "        df_sum.to_csv(f'output/{output_path}/tables/latest_common_expanded_{definition}.csv')\n",
    "            \n",
    "def state_change(df_clean, definitions, other_vars, output_path):\n",
    "    for definition in definitions:\n",
    "        vars = [s for s in other_vars if s.startswith(definition)]\n",
    "        df_subset = df_clean[\n",
    "            [definition]+vars\n",
    "        ].replace(0,np.nan).set_index(definition).reset_index()\n",
    "        df_subset['n'] = 1\n",
    "        # Count\n",
    "        df_subset2 = df_subset.loc[~df_subset[definition].isna()]\n",
    "        df_subset3 = redact_round_table(df_subset2.groupby(definition).count()).reset_index()\n",
    "        # Set index\n",
    "        df_subset3['index'] = df_subset3[definition].astype(str) + \" (n = \" + df_subset3['n'].astype(int).astype(str) + \")\"\n",
    "        df_out = df_subset3.drop(columns=[definition,'n']).rename(columns = {'index':definition}).set_index(definition)\n",
    "        # Null out the diagonal\n",
    "        # np.fill_diagonal(df_out.values, np.nan)\n",
    "        # df_out = df_out.where(~df_out.isna(), '-')\n",
    "    \n",
    "        #display(df_out)\n",
    "        df_out.to_csv(f'output/{output_path}/tables/state_change_{definition}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = import_clean(input_path, definitions, other_vars_combined, demographic_covariates, \n",
    "                    clinical_covariates, null, date_min, date_max, \n",
    "                    time_delta, output_path, code_dict, dates)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bd7deed66f04c8f1cb07fbe5b34625baefe8e7d41af3b53c9662fc8ba397df1b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
