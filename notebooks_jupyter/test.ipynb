{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ CONFIGURE OPTIONS HERE ################################\n",
    "\n",
    "# Import file\n",
    "input_path = \"C:/Users/candrews/Documents/GitHub/ethnicity-short-data-report/output/data/input.feather\"\n",
    "\n",
    "# Definitions\n",
    "definitions = [\"ethnicity_5\", \"ethnicity_new_5\", \"ethnicity_primis_5\"]\n",
    "\n",
    "# Code dictionary\n",
    "code_dict = {\n",
    "    \"imd\": {\n",
    "        0: \"Unknown\",\n",
    "        1: \"1 Most deprived\",\n",
    "        2: \"2\",\n",
    "        3: \"3\",\n",
    "        4: \"4\",\n",
    "        5: \"5 Least deprived\",\n",
    "    },\n",
    "    \"ethnicity_5\": {1: \"White\", 2: \"Mixed\", 3: \"Asian\", 4: \"Black\", 5: \"Other\"},\n",
    "    \"ethnicity_new_5\": {1: \"White\", 2: \"Mixed\", 3: \"Asian\", 4: \"Black\", 5: \"Other\"},\n",
    "    \"ethnicity_primis_5\": {1: \"White\", 2: \"Mixed\", 3: \"Asian\", 4: \"Black\", 5: \"Other\"},\n",
    "}\n",
    "\n",
    "# Other variables to include\n",
    "other_vars = [\"white\", \"mixed\", \"asian\", \"black\", \"other\"]\n",
    "other_vars_combined = [x + \"_\" + y for x in definitions for y in other_vars]\n",
    "\n",
    "# Restrict to registered as of index date\n",
    "registered = True\n",
    "reg = \"registered\"\n",
    "\n",
    "eth_dates = True\n",
    "# Dates\n",
    "dates = False\n",
    "date_min = \"\"\n",
    "date_max = \"\"\n",
    "time_delta = \"\"\n",
    "\n",
    "# Min/max range\n",
    "min_range = 4\n",
    "max_range = 200\n",
    "\n",
    "# Null value – could be multiple values in a list [0,'0',NA]\n",
    "null = [0, \"0\"]\n",
    "\n",
    "# Covariates\n",
    "demographic_covariates = [\"age_band\", \"sex\", \"region\", \"imd\"]\n",
    "clinical_covariates = [\"dementia\", \"diabetes\", \"hypertension\", \"learning_disability\"]\n",
    "\n",
    "# Output filepath\n",
    "output_path = \"phenotype_validation_ethnicity/5\"\n",
    "if registered == True:\n",
    "    output_path = output_path + \"/registered\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import itertools\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from functools import reduce\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def redact_round_table(df_in):\n",
    "    \"\"\"Redacts counts <= 5 and rounds counts to nearest 5\"\"\"\n",
    "    df_out = df_in.where(df_in > 5, np.nan).apply(lambda x: 5 * round(x / 5))\n",
    "    return df_out\n",
    "\n",
    "\n",
    "def import_clean(\n",
    "    input_path,\n",
    "    definitions,\n",
    "    other_vars,\n",
    "    demographic_covariates,\n",
    "    clinical_covariates,\n",
    "    reg,\n",
    "    null,\n",
    "    date_min,\n",
    "    date_max,\n",
    "    time_delta,\n",
    "    output_path,\n",
    "    code_dict=\"\",\n",
    "    dates=False,\n",
    "    registered=True,\n",
    "    eth_dates = True,\n",
    "):\n",
    "    # Import\n",
    "    df_import = pd.read_feather(input_path)\n",
    "\n",
    "    # restrict to registered as of indes date\n",
    "    if registered == True:\n",
    "        df_import = df_import[df_import[reg]]\n",
    "\n",
    "    # Dates\n",
    "    if dates == True:\n",
    "        date_vars = [definition + \"_date\" for definition in definitions]\n",
    "        # Create variable that captures difference in measurement dates\n",
    "        date_diff_vars = []\n",
    "        # Define start and end dates\n",
    "        start_date = datetime.datetime.strptime(date_min, \"%Y-%m-%d\")\n",
    "        end_date = datetime.datetime.strptime(date_max, \"%Y-%m-%d\")\n",
    "        for definition in definitions:\n",
    "            # Remove OpenSAFELY null dates\n",
    "            df_import.loc[\n",
    "                df_import[definition + \"_date\"] == \"1900-01-01\", definition + \"_date\"\n",
    "            ] = np.nan\n",
    "            # Limit to period of interest\n",
    "            df_import[definition + \"_date\"] = pd.to_datetime(\n",
    "                df_import[definition + \"_date\"]\n",
    "            )\n",
    "            df_import.loc[\n",
    "                df_import[definition + \"_date\"] < start_date, definition + \"_date\"\n",
    "            ] = np.nan\n",
    "            df_import.loc[\n",
    "                df_import[definition + \"_date\"] > end_date, definition + \"_date\"\n",
    "            ] = np.nan\n",
    "            # Remove the measurement if outside the date parameters\n",
    "            df_import.loc[df_import[definition + \"_date\"].isna(), definition] = np.nan\n",
    "            df_import\n",
    "            # Create difference between measurement dates\n",
    "            df_import[definition + \"_date\"] = (\n",
    "                df_import[definition + \"_date\"]\n",
    "                .dt.to_period(time_delta)\n",
    "                .dt.to_timestamp()\n",
    "            )\n",
    "            df_import = df_import.sort_values(by=[\"patient_id\", definition + \"_date\"])\n",
    "            df_import[\"date_diff_\" + definition] = round(\n",
    "                df_import.groupby(\"patient_id\")[definition + \"_date\"].diff()\n",
    "                / np.timedelta64(1, time_delta)\n",
    "            )\n",
    "            date_diff_vars.append(\"date_diff_\" + definition)\n",
    "    else:\n",
    "        date_vars = []\n",
    "        date_diff_vars = []\n",
    "    # Codes\n",
    "    if code_dict != \"\":\n",
    "        for key in code_dict:\n",
    "            df_import[key] = df_import[key].astype(float)\n",
    "            df_import[key] = df_import[key].replace(code_dict[key])\n",
    "    # Subset to relevant columns\n",
    "    if eth_dates:\n",
    "        ethnicity_dates=[\n",
    "            f\"{definition}_date\"\n",
    "            for definition in definitions\n",
    "        ]\n",
    "    df_clean = df_import[\n",
    "        [\"patient_id\"]\n",
    "        + definitions\n",
    "        + other_vars\n",
    "        + date_vars\n",
    "        + date_diff_vars\n",
    "        + demographic_covariates\n",
    "        + clinical_covariates\n",
    "        + ethnicity_dates\n",
    "    ]\n",
    "\n",
    "    # Limit to relevant date range\n",
    "    df_clean = df_clean.sort_values(by=\"patient_id\").reset_index(drop=True)\n",
    "    # Set null values to nan\n",
    "    for definition in definitions:\n",
    "        df_clean.loc[df_clean[definition].isin(null), definition] = np.nan\n",
    "    # Create order for categorical variables\n",
    "    for group in demographic_covariates + clinical_covariates:\n",
    "        if df_clean[group].dtype.name == \"category\":\n",
    "            li_order = sorted(df_clean[group].dropna().unique().tolist())\n",
    "            df_clean[group] = df_clean[group].cat.reorder_categories(\n",
    "                li_order, ordered=True\n",
    "            )\n",
    "    # Mark patients with value filled/missing for each definition\n",
    "    li_filled = []\n",
    "    for definition in definitions:\n",
    "        df_fill = pd.DataFrame(\n",
    "            df_clean.groupby(\"patient_id\")[definition].any().astype(\"int\")\n",
    "        ).rename(columns={definition: definition + \"_filled\"})\n",
    "        df_fill[definition + \"_missing\"] = 1 - df_fill[definition + \"_filled\"]\n",
    "        li_filled.append(df_fill)\n",
    "\n",
    "    df_filled = pd.concat(li_filled, axis=1)\n",
    "    # Remove list from memory\n",
    "    del li_filled\n",
    "    df_clean = df_clean.merge(df_filled, on=\"patient_id\")\n",
    "\n",
    "    # Flag all filled/all missing\n",
    "    li_col_filled = [col for col in df_clean.columns if col.endswith(\"_filled\")]\n",
    "    li_col_missing = [col for col in df_clean.columns if col.endswith(\"_missing\")]\n",
    "    df_clean[\"all_filled\"] = (\n",
    "        df_clean[li_col_filled].sum(axis=1) == len(definitions)\n",
    "    ).astype(int)\n",
    "    df_clean[\"all_missing\"] = (\n",
    "        df_clean[li_col_missing].sum(axis=1) == len(definitions)\n",
    "    ).astype(int)\n",
    "\n",
    "    # Check whether output paths exist or not, create if missing\n",
    "    path_tables = f\"output/{output_path}/tables\"\n",
    "    path_figures = f\"output/{output_path}/figures\"\n",
    "    li_filepaths = [path_tables, path_figures]\n",
    "\n",
    "    for filepath in li_filepaths:\n",
    "        exists = os.path.exists(filepath)\n",
    "        if not exists:\n",
    "            os.makedirs(filepath)\n",
    "\n",
    "    return df_clean\n",
    "\n",
    "\n",
    "def patient_counts(\n",
    "    df_clean,\n",
    "    definitions,\n",
    "    demographic_covariates,\n",
    "    clinical_covariates,\n",
    "    output_path,\n",
    "    code_dict=\"\",\n",
    "    categories=False,\n",
    "    missing=False,\n",
    "):\n",
    "    suffix = \"_filled\"\n",
    "    subgroup = \"with records\"\n",
    "    overlap = \"all_filled\"\n",
    "    if missing == True:\n",
    "        suffix = \"_missing\"\n",
    "        subgroup = \"missing records\"\n",
    "        overlap = \"all_missing\"\n",
    "    if categories == True:\n",
    "        li_cat_def = []\n",
    "        li_cat = (\n",
    "            df_clean[definitions[0]]\n",
    "            .dropna()\n",
    "            .astype(str)\n",
    "            .sort_values()\n",
    "            .unique()\n",
    "            .tolist()\n",
    "        )\n",
    "        for x in li_cat:\n",
    "            for definition in definitions:\n",
    "                df_clean.loc[df_clean[definition] == x, f\"{x}_{definition}_filled\"] = 1\n",
    "                li_cat_def.append(f\"-{x}-{definition}\")\n",
    "        if code_dict != \"\":\n",
    "            for i in code_dict[definition]:\n",
    "                li_cat_def = list(\n",
    "                    map(\n",
    "                        lambda x: x.replace(code_dict[definition][i], str(i)),\n",
    "                        li_cat_def,\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            li_cat_def = sorted(li_cat_def)\n",
    "            for i in code_dict[definition]:\n",
    "                li_cat_def = list(\n",
    "                    map(\n",
    "                        lambda x: x.replace(\n",
    "                            f\"-{str(i)}-\", f\"{code_dict[definition][i]}_\"\n",
    "                        ),\n",
    "                        li_cat_def,\n",
    "                    )\n",
    "                )\n",
    "        definitions = li_cat_def\n",
    "\n",
    "    # All with measurement\n",
    "    li_filled = []\n",
    "    for definition in definitions:\n",
    "        df_temp = (\n",
    "            df_clean[[\"patient_id\", definition + suffix]]\n",
    "            .drop_duplicates()\n",
    "            .dropna()\n",
    "            .set_index(\"patient_id\")\n",
    "        )\n",
    "        li_filled.append(df_temp)\n",
    "\n",
    "    df_temp = (\n",
    "        df_clean[[\"patient_id\", overlap]]\n",
    "        .drop_duplicates()\n",
    "        .dropna()\n",
    "        .set_index(\"patient_id\")\n",
    "    )\n",
    "    li_filled.append(df_temp)\n",
    "\n",
    "    df_temp2 = pd.concat(li_filled, axis=1)\n",
    "    df_temp2[\"population\"] = 1\n",
    "    # Remove list from memory\n",
    "    del li_filled\n",
    "    df_all = pd.DataFrame(df_temp2.sum()).T\n",
    "    df_all[\"group\"], df_all[\"subgroup\"] = [\"all\", subgroup]\n",
    "    df_all = df_all.set_index([\"group\", \"subgroup\"])\n",
    "\n",
    "    # By group\n",
    "    li_group = []\n",
    "    for group in demographic_covariates + clinical_covariates:\n",
    "        li_filled_group = []\n",
    "        for definition in definitions:\n",
    "            df_temp = (\n",
    "                df_clean[[\"patient_id\", definition + suffix, group]]\n",
    "                .drop_duplicates()\n",
    "                .dropna()\n",
    "                .reset_index(drop=True)\n",
    "            )\n",
    "            li_filled_group.append(df_temp)\n",
    "\n",
    "        df_temp = (\n",
    "            df_clean[[\"patient_id\", overlap, group]]\n",
    "            .drop_duplicates()\n",
    "            .dropna()\n",
    "            .reset_index(drop=True)\n",
    "        )\n",
    "        li_filled_group.append(df_temp)\n",
    "\n",
    "        df_reduce = reduce(\n",
    "            lambda df1, df2: pd.merge(df1, df2, on=[\"patient_id\", group], how=\"outer\"),\n",
    "            li_filled_group,\n",
    "        )\n",
    "        df_reduce[\"population\"] = 1\n",
    "        # Remove list from memory\n",
    "        del li_filled_group\n",
    "        df_reduce2 = (\n",
    "            df_reduce.sort_values(by=group)\n",
    "            .drop(columns=[\"patient_id\"])\n",
    "            .groupby(group)\n",
    "            .sum()\n",
    "            .reset_index()\n",
    "        )\n",
    "        df_reduce2[\"group\"] = group\n",
    "        df_reduce2 = df_reduce2.rename(columns={group: \"subgroup\"})\n",
    "        li_group.append(df_reduce2)\n",
    "    df_all_group = pd.concat(li_group, axis=0, ignore_index=True).set_index(\n",
    "        [\"group\", \"subgroup\"]\n",
    "    )\n",
    "    # Remove list from memory\n",
    "    del li_group\n",
    "\n",
    "    # Redact\n",
    "    df_append = redact_round_table(df_all.append(df_all_group))\n",
    "\n",
    "    # Create percentage columns\n",
    "    for definition in definitions:\n",
    "        df_append[definition + \"_pct\"] = round(\n",
    "            (df_append[definition + suffix].div(df_append[\"population\"])) * 100, 1\n",
    "        )\n",
    "    df_append[overlap + \"_pct\"] = round(\n",
    "        (df_append[overlap].div(df_append[\"population\"])) * 100, 1\n",
    "    )\n",
    "\n",
    "    # Final redaction step\n",
    "    df_append = df_append.where(~df_append.isna(), \"-\")\n",
    "\n",
    "    # Combine count and percentage columns\n",
    "    for definition in definitions:\n",
    "        df_append[definition] = (\n",
    "            df_append[definition + suffix].astype(str)\n",
    "            + \" (\"\n",
    "            + df_append[definition + \"_pct\"].astype(str)\n",
    "            + \")\"\n",
    "        )\n",
    "        df_append = df_append.drop(columns=[definition + suffix, definition + \"_pct\"])\n",
    "    df_append[overlap] = (\n",
    "        df_append[overlap].astype(str)\n",
    "        + \" (\"\n",
    "        + df_append[overlap + \"_pct\"].astype(str)\n",
    "        + \")\"\n",
    "    )\n",
    "    df_append = df_append.drop(columns=[overlap + \"_pct\"])\n",
    "\n",
    "    # Column order\n",
    "    li_col_order = []\n",
    "    for definition in definitions:\n",
    "        li_col_order.append(definition)\n",
    "    if eth_dates:\n",
    "        li_col_order.append(definition+\"_date\")\n",
    "    li_col_order.append(overlap)\n",
    "    li_col_order.append(\"population\")\n",
    "\n",
    "    df_all_redact = df_append[li_col_order]\n",
    "    df_all_redact.columns = df_all_redact.columns.str.replace(\"_\", \" \")\n",
    "    display(df_all_redact)\n",
    "    if categories == False:\n",
    "        df_all_redact.to_csv(f\"output/{output_path}/tables/patient_counts{suffix}.csv\")\n",
    "    if categories == True:\n",
    "        df_all_redact.to_csv(\n",
    "            f\"output/{output_path}/tables/patient_counts_by_categories{suffix}.csv\"\n",
    "        )\n",
    "\n",
    "\n",
    "def display_heatmap(df_clean, definitions, output_path):\n",
    "    # All with measurement\n",
    "    li_filled = []\n",
    "    for definition in definitions:\n",
    "        df_temp = df_clean[[\"patient_id\"]].drop_duplicates().set_index(\"patient_id\")\n",
    "        df_temp[definition + \"_filled\"] = 1\n",
    "        df_temp = (\n",
    "            df_clean[[\"patient_id\", definition + \"_filled\"]]\n",
    "            .drop_duplicates()\n",
    "            .dropna()\n",
    "            .set_index(\"patient_id\")\n",
    "        )\n",
    "        li_filled.append(df_temp)\n",
    "\n",
    "    # Prepare data for heatmap input\n",
    "    df_temp2 = pd.concat(li_filled, axis=1)\n",
    "    # Remove list from memory\n",
    "    del li_filled\n",
    "    df_transform = df_temp2.replace(np.nan, 0)\n",
    "    df_dot = redact_round_table(df_transform.T.dot(df_transform))\n",
    "\n",
    "    # Create mask to eliminate duplicates in heatmap\n",
    "    mask = np.triu(np.ones_like(df_dot))\n",
    "    np.fill_diagonal(mask[::1], 0)\n",
    "\n",
    "    # Draw the heatmap with the mask\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    sns.heatmap(df_dot, annot=True, mask=mask, fmt=\"g\", cmap=\"YlGnBu\", vmin=0)\n",
    "    # plt.show()\n",
    "    plt.savefig(f\"output/{output_path}/figures/heatmap.png\")\n",
    "\n",
    "\n",
    "def records_over_time(\n",
    "    df_clean, definitions, demographic_covariates, clinical_covariates, output_path\n",
    "):\n",
    "    li_df = []\n",
    "    for definition in definitions:\n",
    "        df_grouped = (\n",
    "            df_clean[[definition + \"_date\", definition]]\n",
    "            .groupby(definition + \"_date\")\n",
    "            .count()\n",
    "            .reset_index()\n",
    "            .rename(columns={definition + \"_date\": \"date\"})\n",
    "            .set_index(\"date\")\n",
    "        )\n",
    "        li_df.append(redact_round_table(df_grouped))\n",
    "    df_all_time = (\n",
    "        pd.concat(li_df)\n",
    "        .stack()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"level_1\": \"variable\", 0: \"value\"})\n",
    "    )\n",
    "    # Remove list from memory\n",
    "    del li_df\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    fig.autofmt_xdate()\n",
    "    sns.lineplot(\n",
    "        x=\"date\", y=\"value\", hue=\"variable\", data=df_all_time, ax=ax\n",
    "    ).set_title(\"New records by month\")\n",
    "    ax.legend().set_title(\"\")\n",
    "    plt.savefig(f\"output/{output_path}/figures/records_over_time.png\")\n",
    "\n",
    "    for group in demographic_covariates + clinical_covariates:\n",
    "        for definition in definitions:\n",
    "            df_grouped = (\n",
    "                df_clean[[definition + \"_date\", definition, group]]\n",
    "                .groupby([definition + \"_date\", group])\n",
    "                .count()\n",
    "                .reset_index()\n",
    "                .rename(columns={definition + \"_date\": \"date\"})\n",
    "                .set_index([\"date\", group])\n",
    "            )\n",
    "            df_time = redact_round_table(df_grouped).reset_index()\n",
    "            fig, ax = plt.subplots(figsize=(12, 8))\n",
    "            fig.autofmt_xdate()\n",
    "            sns.lineplot(\n",
    "                x=\"date\", y=definition, hue=group, data=df_time, ax=ax\n",
    "            ).set_title(f\"{definition} recorded by {group} and month\")\n",
    "            ax.legend().set_title(\"\")\n",
    "            plt.savefig(\n",
    "                f\"output/{output_path}/figures/records_over_time_{definition}_{group}.png\"\n",
    "            )\n",
    "\n",
    "\n",
    "def report_distribution(df_occ, definitions, num_definitions, output_path, group=\"\"):\n",
    "    \"\"\"\n",
    "    Plots histogram or boxplots of distribution\n",
    "    \"\"\"\n",
    "    if group == \"\":\n",
    "        if num_definitions == 1:\n",
    "            for definition in definitions:\n",
    "\n",
    "                avg_value = pd.DataFrame(df_occ[definition].agg([\"mean\", \"count\"]))\n",
    "                if avg_value.loc[\"count\"][0] > 6:\n",
    "                    avg_value.loc[\"count\"][0] = 5 * round(avg_value.loc[\"count\"][0] / 5)\n",
    "                    print(f\"Average {definition}:\\n\")\n",
    "                    # display(avg_value)\n",
    "                    avg_value.to_csv(\n",
    "                        f\"output/{output_path}/tables/avg_value_{definition}.csv\"\n",
    "                    )\n",
    "                    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "                    hist_data = df_occ[definition].loc[~df_occ[definition].isna()]\n",
    "                    plt.hist(hist_data, bins=np.arange(min(hist_data), max(hist_data)))\n",
    "                    plt.title(\"Distribution of \" + definition)\n",
    "                    # plt.show()\n",
    "                    plt.savefig(f\"output/{output_path}/figures/distribution.png\")\n",
    "                else:\n",
    "                    print(\"Table and plot redacted due to low counts.\")\n",
    "\n",
    "        else:\n",
    "            df_bp = df_occ[definitions]\n",
    "            avg = pd.DataFrame(df_bp.mean(), columns=[\"mean\"])\n",
    "            ct = pd.DataFrame(df_bp.count(), columns=[\"count\"])\n",
    "            avg_value = avg.merge(ct, left_index=True, right_index=True)\n",
    "            # Redact and round values\n",
    "            avg_value[\"count\"] = (\n",
    "                avg_value[\"count\"]\n",
    "                .where(avg_value[\"count\"] > 5, np.nan)\n",
    "                .apply(lambda x: 5 * round(x / 5) if ~np.isnan(x) else x)\n",
    "            )\n",
    "            print(\"Averages:\\n\")\n",
    "            # display(avg_value)\n",
    "            avg_value.to_csv(f\"output/{output_path}/tables/avg_value.csv\")\n",
    "            fig, ax = plt.subplots(figsize=(12, 8))\n",
    "            sns.boxplot(data=df_bp, showfliers=False)\n",
    "            plt.title(\"Distributions of values\")\n",
    "            # plt.show()\n",
    "            plt.savefig(f\"output/{output_path}/figures/distribution.png\")\n",
    "    else:\n",
    "        if num_definitions == 1:\n",
    "            for definition in definitions:\n",
    "                df_bp = df_occ[[group] + [definition]]\n",
    "                avg_value = df_bp.groupby(group)[definition].agg([\"mean\", \"count\"])\n",
    "                # Redact and round values\n",
    "                avg_value[\"count\"] = (\n",
    "                    avg_value[\"count\"]\n",
    "                    .where(avg_value[\"count\"] > 5, np.nan)\n",
    "                    .apply(lambda x: 5 * round(x / 5) if ~np.isnan(x) else x)\n",
    "                )\n",
    "                avg_value.loc[avg_value[\"count\"].isna(), [\"count\", \"mean\"]] = [\"-\", \"-\"]\n",
    "                print(f\"Averages by {group}:\\n\")\n",
    "                # display(avg_value)\n",
    "                avg_value.to_csv(\n",
    "                    f\"output/{output_path}/tables/avg_value_{definition}_{group}.csv\"\n",
    "                )\n",
    "                null_index = avg_value[avg_value[\"count\"] == \"-\"].index.tolist()\n",
    "                fig, ax = plt.subplots(figsize=(12, 8))\n",
    "                sns.boxplot(\n",
    "                    x=group,\n",
    "                    y=definition,\n",
    "                    data=df_bp.loc[~df_bp[group].isin(null_index)],\n",
    "                    showfliers=False,\n",
    "                )\n",
    "                plt.title(f\"Distributions by {group}\")\n",
    "                # plt.show()\n",
    "                plt.savefig(f\"output/{output_path}/figures/distribution_{group}.png\")\n",
    "        else:\n",
    "            if df_occ[group].dtype == \"bool\":\n",
    "                df_occ[group] = df_occ[group].apply(lambda x: str(x))\n",
    "            df_occ = df_occ.loc[~df_occ[group].isna()]  # Drop nan categories\n",
    "            df_bp = df_occ[[group] + definitions]\n",
    "            avg = df_bp.groupby(group).mean().add_prefix(\"avg_\")\n",
    "            ct = df_bp.groupby(group).count().add_prefix(\"ct_\")\n",
    "            avg_value = avg.merge(ct, left_on=group, right_on=group)\n",
    "            for definition in definitions:\n",
    "                # Redact and round values\n",
    "                avg_value[\"ct_\" + definition] = (\n",
    "                    avg_value[\"ct_\" + definition]\n",
    "                    .where(avg_value[\"ct_\" + definition] > 5, np.nan)\n",
    "                    .apply(lambda x: 5 * round(x / 5) if ~np.isnan(x) else x)\n",
    "                )\n",
    "                avg_value.loc[\n",
    "                    avg_value[\"ct_\" + definition].isna(),\n",
    "                    [\"ct_\" + definition, \"avg_\" + definition],\n",
    "                ] = [\"-\", \"-\"]\n",
    "            print(f\"Averages by {group}:\\n\")\n",
    "            # display(avg_value)\n",
    "            avg_value.to_csv(f\"output/{output_path}/tables/avg_value_{group}.csv\")\n",
    "            for definition in definitions:\n",
    "                null_index = []\n",
    "                null_index = avg_value[\n",
    "                    avg_value[\"ct_\" + definition] == \"-\"\n",
    "                ].index.tolist()\n",
    "                df_bp.loc[df_bp[group].isin(null_index), definition] = np.nan\n",
    "            fig, ax = plt.subplots(figsize=(12, 8))\n",
    "            df_plot = df_bp.melt(id_vars=group, value_vars=definitions)\n",
    "            sns.boxplot(\n",
    "                x=group, y=\"value\", hue=\"variable\", data=df_plot, showfliers=False\n",
    "            )\n",
    "            plt.title(f\"Distributions by {group}\")\n",
    "            # plt.show()\n",
    "            plt.savefig(f\"output/{output_path}/figures/distribution_{group}.png\")\n",
    "\n",
    "\n",
    "def report_out_of_range(\n",
    "    df_occ,\n",
    "    definitions,\n",
    "    min_range,\n",
    "    max_range,\n",
    "    num_definitions,\n",
    "    null,\n",
    "    output_path,\n",
    "    group=\"\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Reports number of measurements outside of defined range\n",
    "    \"\"\"\n",
    "\n",
    "    def q25(x):\n",
    "        return x.quantile(0.25)\n",
    "\n",
    "    def q75(x):\n",
    "        return x.quantile(0.75)\n",
    "\n",
    "    li_dfs = []\n",
    "\n",
    "    df_oor = df_occ\n",
    "    for definition in definitions:\n",
    "        df_oor.loc[\n",
    "            (df_oor[definition] < min_range) | (df_oor[definition] > max_range),\n",
    "            \"out_of_range_\" + definition,\n",
    "        ] = 1\n",
    "        # Make definitions null if not out of range or empty\n",
    "        df_oor[\"oor_\" + definition] = df_oor[definition]\n",
    "        df_oor.loc[\n",
    "            (df_oor[\"out_of_range_\" + definition] != 1)\n",
    "            | (df_oor[definition].isin(null)),\n",
    "            \"oor_\" + definition,\n",
    "        ] = np.nan\n",
    "        if group == \"\":\n",
    "            try:\n",
    "                df_out = df_oor.agg(\n",
    "                    count=(\"oor_\" + definition, \"count\"),\n",
    "                    mean=(\"oor_\" + definition, \"mean\"),\n",
    "                    pct25=(\"oor_\" + definition, q25),\n",
    "                    pct75=(\"oor_\" + definition, q75),\n",
    "                )\n",
    "            except:\n",
    "                df_out = pd.DataFrame(\n",
    "                    [\n",
    "                        [\"count\", 0],\n",
    "                        [\"mean\", np.nan],\n",
    "                        [\"pct25\", np.nan],\n",
    "                        [\"pct75\", np.nan],\n",
    "                    ],\n",
    "                    columns=[\"index\", \"oor_\" + definition],\n",
    "                ).set_index(\"index\")\n",
    "            if df_out.loc[\"count\"][\"oor_\" + definition] > 6:\n",
    "                df_out.loc[\"count\"][\"oor_\" + definition] = 5 * round(\n",
    "                    df_out.loc[\"count\"][\"oor_\" + definition] / 5\n",
    "                )\n",
    "            else:\n",
    "                df_out[\"oor_\" + definition] = \"-\"\n",
    "        else:\n",
    "            df_out = (\n",
    "                df_oor.groupby(group)[\"oor_\" + definition]\n",
    "                .agg(\n",
    "                    [\n",
    "                        (\"count\", \"count\"),\n",
    "                        (\"mean\", \"mean\"),\n",
    "                        (\"pct25\", q25),\n",
    "                        (\"pct75\", q75),\n",
    "                    ]\n",
    "                )\n",
    "                .add_suffix(\"_\" + definition)\n",
    "            )\n",
    "            df_out.loc[\n",
    "                df_out[\"count_\" + definition] > 5, \"count_\" + definition\n",
    "            ] = 5 * round(df_out[\"count_\" + definition] / 5)\n",
    "            df_out.loc[\n",
    "                df_out[\"count_\" + definition] < 6,\n",
    "                [\n",
    "                    \"count_\" + definition,\n",
    "                    \"mean_\" + definition,\n",
    "                    \"pct25_\" + definition,\n",
    "                    \"pct75_\" + definition,\n",
    "                ],\n",
    "            ] = [\"-\", \"-\", \"-\", \"-\"]\n",
    "        li_dfs.append(df_out)\n",
    "\n",
    "    if num_definitions == 1:\n",
    "        # display(df_out)\n",
    "        df_out.to_csv(f\"output/{output_path}/tables/out_of_range.csv\")\n",
    "        # Remove list from memory\n",
    "        del li_dfs\n",
    "        if group == \"\":\n",
    "            if df_out[\"oor_\" + definition][\"count\"] != \"-\":\n",
    "                df_plot = df_oor[\"oor_\" + definition]\n",
    "                fig, ax = plt.subplots(figsize=(12, 8))\n",
    "                plt.hist(df_plot)\n",
    "                plt.title(\"Distribution of out of range \" + definition)\n",
    "                # plt.show()\n",
    "                plt.savefig(f\"output/{output_path}/figures/out_of_range.png\")\n",
    "            else:\n",
    "                print(\"Plot redacted due to low counts.\")\n",
    "        else:\n",
    "            df_oor = df_oor.loc[~df_oor[group].isna()]\n",
    "            for definition in definitions:\n",
    "                null_index = df_out[df_out[\"count_\" + definition] == \"-\"].index.tolist()\n",
    "                df_oor.loc[df_oor[group].isin(null_index), \"oor_\" + definition] = np.nan\n",
    "                df_bp = df_oor[[group] + [\"oor_\" + definition]]\n",
    "                if df_bp[\"oor_\" + definition].sum() > 0:\n",
    "                    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "                    sns.boxplot(\n",
    "                        x=group, y=\"oor_\" + definition, data=df_bp, showfliers=False\n",
    "                    )\n",
    "                    plt.title(f\"Distribution of out of range values by {group}\")\n",
    "                    plt.show()\n",
    "                    plt.savefig(\n",
    "                        f\"output/{output_path}/figures/out_of_range_{group}.png\"\n",
    "                    )\n",
    "                else:\n",
    "                    print(\"Plot redacted due to low counts.\")\n",
    "    else:\n",
    "        df_merged = reduce(\n",
    "            lambda left, right: pd.merge(\n",
    "                left, right, left_index=True, right_index=True\n",
    "            ),\n",
    "            li_dfs,\n",
    "        )\n",
    "        # Remove list from memory\n",
    "        del li_dfs\n",
    "        # display(df_merged)\n",
    "        if group == \"\":\n",
    "            df_merged.to_csv(f\"output/{output_path}/tables/out_of_range.csv\")\n",
    "            cols = [\"oor_\" + definition for definition in definitions]\n",
    "            df_bp = df_oor[cols]\n",
    "            if df_merged[\"oor_\" + definition][\"count\"] == \"-\":\n",
    "                df_bp[\"oor_\" + definition] = np.nan\n",
    "            try:\n",
    "                fig, ax = plt.subplots(figsize=(12, 8))\n",
    "                sns.boxplot(data=df_bp, showfliers=False)\n",
    "                plt.title(\"Distribution of out of range values\")\n",
    "                # plt.show()\n",
    "                plt.savefig(f\"output/{output_path}/figures/out_of_range.png\")\n",
    "            except:\n",
    "                print(\"Plot redacted due to low counts.\")\n",
    "        else:\n",
    "            df_merged.to_csv(f\"output/{output_path}/tables/out_of_range_{group}.csv\")\n",
    "            df_oor = df_oor.loc[~df_oor[group].isna()]\n",
    "            for definition in definitions:\n",
    "                null_index = df_merged[\n",
    "                    df_merged[\"count_\" + definition] == \"-\"\n",
    "                ].index.tolist()\n",
    "                df_oor.loc[df_oor[group].isin(null_index), \"oor_\" + definition] = np.nan\n",
    "            if df_oor[group].dtype == \"bool\":\n",
    "                df_oor[group] = df_oor[group].apply(lambda x: str(x))\n",
    "            cols = [\"oor_\" + definition for definition in definitions]\n",
    "            df_bp = df_oor[[group] + cols]\n",
    "            df_plot = df_bp.melt(id_vars=group, value_vars=cols)\n",
    "            if df_plot[\"value\"].sum() > 0:\n",
    "                fig, ax = plt.subplots(figsize=(12, 8))\n",
    "                sns.boxplot(\n",
    "                    x=group, y=\"value\", hue=\"variable\", data=df_plot, showfliers=False\n",
    "                )\n",
    "                plt.title(f\"Distribution of out of range values by {group}\")\n",
    "                # plt.show()\n",
    "                plt.savefig(f\"output/{output_path}/figures/out_of_range_{group}.png\")\n",
    "            else:\n",
    "                print(\"Plot redacted due to low counts.\")\n",
    "\n",
    "\n",
    "def report_update_frequency(\n",
    "    df_occ, definitions, time_delta, num_definitions, output_path, group=\"\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots histogram or boxplot of update frequency and reports average update frequency\n",
    "    \"\"\"\n",
    "    if group == \"\":\n",
    "        if num_definitions == 1:\n",
    "            for definition in definitions:\n",
    "                avg_update_freq = df_occ.agg(\n",
    "                    avg_diff=(f\"date_diff_{definition}\", \"mean\"),\n",
    "                    count=(f\"date_diff_{definition}\", \"count\"),\n",
    "                )\n",
    "                if avg_update_freq.loc[\"count\"][0] > 6:\n",
    "                    avg_update_freq.loc[\"count\"][0] = 5 * round(\n",
    "                        avg_update_freq.loc[\"count\"][0] / 5\n",
    "                    )\n",
    "                    print(\n",
    "                        f\"Average update frequency of {definition} by {time_delta}:\\n\"\n",
    "                    )\n",
    "                    # display(avg_update_freq)\n",
    "                    avg_update_freq.to_csv(\n",
    "                        f\"output/{output_path}/tables/avg_update_frequency_{definition}.csv\"\n",
    "                    )\n",
    "                    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "                    plt.hist(df_occ[\"date_diff_\" + definition])\n",
    "                    plt.title(\"Update frequency of \" + definition + f\" by {time_delta}\")\n",
    "                    # plt.show()\n",
    "                    plt.savefig(\n",
    "                        f\"output/{output_path}/figures/avg_update_frequency_{definition}.png\"\n",
    "                    )\n",
    "                else:\n",
    "                    print(\"Table and plot redacted due to low counts.\")\n",
    "        else:\n",
    "            cols = [\"date_diff_\" + x for x in definitions]\n",
    "            df_bp = df_occ[cols]\n",
    "            avg_update = pd.DataFrame(df_bp.mean(), columns=[\"avg_diff\"])\n",
    "            ct_update = pd.DataFrame(df_bp.count(), columns=[\"count\"])\n",
    "            avg_update_freq = avg_update.merge(\n",
    "                ct_update, left_index=True, right_index=True\n",
    "            )\n",
    "            # Redact and round values\n",
    "            avg_update_freq[\"count\"] = (\n",
    "                avg_update_freq[\"count\"]\n",
    "                .where(avg_update_freq[\"count\"] > 5, np.nan)\n",
    "                .apply(lambda x: 5 * round(x / 5) if ~np.isnan(x) else x)\n",
    "            )\n",
    "            print(f\"Average update frequency by {time_delta}:\\n\")\n",
    "            # display(avg_update_freq)\n",
    "            avg_update_freq.to_csv(\n",
    "                f\"output/{output_path}/tables/avg_update_frequency.csv\"\n",
    "            )\n",
    "            fig, ax = plt.subplots(figsize=(12, 8))\n",
    "            null_index = avg_update_freq[avg_update_freq[\"count\"] == \"-\"].index.tolist()\n",
    "            sns.boxplot(data=df_bp.drop(columns=null_index), showfliers=False)\n",
    "            plt.title(f\"Update frequency by {time_delta}\")\n",
    "            # plt.show()\n",
    "            plt.savefig(f\"output/{output_path}/figures/avg_update_frequency.png\")\n",
    "\n",
    "    else:\n",
    "        if num_definitions == 1:\n",
    "            for definition in definitions:\n",
    "                df_bp = df_occ[[group] + [\"date_diff_\" + definition]]\n",
    "                avg_update_freq = (\n",
    "                    df_occ.groupby(group)\n",
    "                    .agg(\n",
    "                        avg_diff=(\"date_diff_\" + definition, \"mean\"),\n",
    "                        count=(\"date_diff_\" + definition, \"count\"),\n",
    "                    )\n",
    "                    .reset_index()\n",
    "                )\n",
    "                # Redact and round values\n",
    "                avg_update_freq[\"count\"] = (\n",
    "                    avg_update_freq[\"count\"]\n",
    "                    .where(avg_update_freq[\"count\"] > 5, np.nan)\n",
    "                    .apply(lambda x: 5 * round(x / 5) if ~np.isnan(x) else x)\n",
    "                )\n",
    "                avg_update_freq.loc[\n",
    "                    avg_update_freq[\"count\"].isna(), [\"count\", \"avg_diff\"]\n",
    "                ] = [\"-\", \"-\"]\n",
    "                print(f\"Average update frequency by {group} and {time_delta}:\\n\")\n",
    "                # display(avg_update_freq)\n",
    "                avg_update_freq.to_csv(\n",
    "                    f\"output/{output_path}/tables/avg_update_frequency_{definition}.csv\"\n",
    "                )\n",
    "                null_index = avg_update_freq[\n",
    "                    avg_update_freq[\"count\"] == \"-\"\n",
    "                ].index.tolist()\n",
    "                fig, ax = plt.subplots(figsize=(12, 8))\n",
    "                sns.boxplot(\n",
    "                    x=group,\n",
    "                    y=\"date_diff_\" + definition,\n",
    "                    data=df_bp.loc[~df_bp[group].isin(null_index)].sort_index(),\n",
    "                    showfliers=False,\n",
    "                )\n",
    "                plt.title(f\"Update frequency by {group} and {time_delta}\")\n",
    "                # plt.show()\n",
    "                plt.savefig(\n",
    "                    f\"output/{output_path}/figures/avg_update_frequency_{definition}.png\"\n",
    "                )\n",
    "        else:\n",
    "            if df_occ[group].dtype == \"bool\":\n",
    "                df_occ[group] = df_occ[group].apply(lambda x: str(x))\n",
    "            df_occ = df_occ.loc[~df_occ[group].isna()]  # Drop nan categories\n",
    "            cols = [\"date_diff_\" + x for x in definitions]\n",
    "            df_sub = df_occ[[group] + cols]\n",
    "            avg_update = df_sub.groupby(group).mean().add_prefix(\"avg_\")\n",
    "            ct_update = df_sub.groupby(group).count().add_prefix(\"ct_\")\n",
    "            avg_update_freq = avg_update.merge(\n",
    "                ct_update, left_on=group, right_on=group\n",
    "            ).sort_index()\n",
    "            for definition in definitions:\n",
    "                # Redact and round values\n",
    "                avg_update_freq[\"ct_date_diff_\" + definition] = (\n",
    "                    avg_update_freq[\"ct_date_diff_\" + definition]\n",
    "                    .where(avg_update_freq[\"ct_date_diff_\" + definition] > 5, np.nan)\n",
    "                    .apply(lambda x: 5 * round(x / 5) if ~np.isnan(x) else x)\n",
    "                )\n",
    "                avg_update_freq.loc[\n",
    "                    avg_update_freq[\"ct_date_diff_\" + definition].isna(),\n",
    "                    [\"ct_date_diff_\" + definition, \"avg_date_diff_\" + definition],\n",
    "                ] = [\"-\", \"-\"]\n",
    "            # Sort by index\n",
    "            print(f\"Average update frequencies by {time_delta}:\\n\")\n",
    "            # display(avg_update_freq)\n",
    "            avg_update_freq.to_csv(\n",
    "                f\"output/{output_path}/tables/avg_update_frequency_{group}.csv\"\n",
    "            )\n",
    "            for definition in definitions:\n",
    "                null_index = []\n",
    "                null_index = avg_update_freq[\n",
    "                    avg_update_freq[\"ct_date_diff_\" + definition] == \"-\"\n",
    "                ].index.tolist()\n",
    "                df_sub.loc[\n",
    "                    df_sub[group].isin(null_index), \"date_diff_\" + definition\n",
    "                ] = np.nan\n",
    "            fig, ax = plt.subplots(figsize=(12, 8))\n",
    "            df_plot = df_sub.melt(id_vars=group, value_vars=cols)\n",
    "            sns.boxplot(\n",
    "                x=group, y=\"value\", hue=\"variable\", data=df_plot, showfliers=False\n",
    "            )\n",
    "            plt.title(f\"Update frequencies by {group} and {time_delta}\")\n",
    "            # plt.show()\n",
    "            plt.savefig(\n",
    "                f\"output/{output_path}/figures/avg_update_frequency_{group}.png\"\n",
    "            )\n",
    "\n",
    "\n",
    "def latest_common_comparison(\n",
    "    df_clean, definitions, other_vars, output_path, code_dict=\"\"\n",
    "):\n",
    "    for definition in definitions:\n",
    "        vars = [s for s in other_vars if s.startswith(definition)]\n",
    "        df_subset = df_clean.loc[~df_clean[definition].isna()]\n",
    "        df_subset = df_subset[[definition] + vars].set_index(definition)\n",
    "        df_subset = df_subset.replace(0, np.nan)\n",
    "        df_subset2 = df_subset.where(df_subset.eq(df_subset.max(1), axis=0))\n",
    "        # add check for tied most common ethnicity\n",
    "        # check=df_subset2.count(axis=1)\n",
    "        # check = df_subset2.loc[check>1]\n",
    "        # display(check)\n",
    "        df_subset_3 = df_subset2.notnull().astype(\"int\").reset_index()\n",
    "        df_sum = redact_round_table(df_subset_3.groupby(definition).sum())\n",
    "        df_counts = pd.DataFrame(\n",
    "            np.diagonal(df_sum),\n",
    "            index=df_sum.index,\n",
    "            columns=[f\"matching (n={np.diagonal(df_sum).sum()})\"],\n",
    "        )\n",
    "\n",
    "        df_sum2 = df_sum.copy(deep=True)\n",
    "        np.fill_diagonal(df_sum2.values, 0)\n",
    "        df_diag = pd.DataFrame(\n",
    "            df_sum2.sum(axis=1),\n",
    "            columns=[f\"not_matching (n={df_sum2.sum(axis=1).sum()})\"],\n",
    "        )\n",
    "        df_out = df_counts.merge(df_diag, right_index=True, left_index=True)\n",
    "\n",
    "        # sort rows by category index\n",
    "        df_out = df_out.reindex(list(code_dict[definition].values()))\n",
    "\n",
    "        df_out = df_out.where(~df_out.isna(), \"-\")\n",
    "        df_out.to_csv(\n",
    "            f\"output/{output_path}/tables/latest_common_simple_{definition}.csv\"\n",
    "        )\n",
    "        df_sum = redact_round_table(df_subset_3.groupby(definition).sum())\n",
    "        # sort columns by category index\n",
    "        df_sum.columns = df_sum.columns.str.replace(definition + \"_\", \"\")\n",
    "        df_sum.columns = df_sum.columns.str.lower()\n",
    "        if code_dict != \"\":\n",
    "            lowerlist = [x.lower() for x in (list(code_dict[definition].values()))]\n",
    "            df_sum = df_sum[lowerlist]\n",
    "        else:\n",
    "            df_sum = df_sum.reindex(sorted(df_sum.columns), axis=1)\n",
    "        # sort rows by category index\n",
    "        df_sum = df_sum.reindex(list(code_dict[definition].values()))\n",
    "        df_sum.columns = df_sum.columns.str.replace(\"_\", \" \")\n",
    "        for col in df_sum.columns:\n",
    "            df_sum = df_sum.rename(columns={col: f\"{col} (n={df_sum[col].sum()})\"})\n",
    "        df_sum = df_sum.where(~df_sum.isna(), \"-\")\n",
    "        df_sum.to_csv(\n",
    "            f\"output/{output_path}/tables/latest_common_expanded_{definition}.csv\"\n",
    "        )\n",
    "\n",
    "\n",
    "def state_change(df_clean, definitions, other_vars, output_path, code_dict=\"\"):\n",
    "    for definition in definitions:\n",
    "        vars = [s for s in other_vars if s.startswith(definition)]\n",
    "        df_subset = (\n",
    "            df_clean[[definition] + vars]\n",
    "            .replace(0, np.nan)\n",
    "            .set_index(definition)\n",
    "            .reset_index()\n",
    "        )\n",
    "        df_subset[\"n\"] = 1\n",
    "        # Count\n",
    "        df_subset2 = df_subset.loc[~df_subset[definition].isna()]\n",
    "        df_subset3 = redact_round_table(\n",
    "            df_subset2.groupby(definition).count()\n",
    "        ).reset_index()\n",
    "        # Set index\n",
    "        ### arrange rows by category value\n",
    "        df_subset3 = df_subset3.set_index(definition)\n",
    "        df_subset3 = df_subset3.reindex(list(code_dict[definition].values()))\n",
    "        df_subset3 = df_subset3.reset_index()\n",
    "        df_subset3[\"index\"] = (\n",
    "            df_subset3[definition].astype(str)\n",
    "            + \" (n = \"\n",
    "            + df_subset3[\"n\"].astype(int).astype(str)\n",
    "            + \")\"\n",
    "        )\n",
    "        df_out = (\n",
    "            df_subset3.drop(columns=[definition, \"n\"])\n",
    "            .rename(columns={\"index\": definition})\n",
    "            .set_index(definition)\n",
    "        )\n",
    "        df_out.columns = df_out.columns.str.replace(definition + \"_\", \"\")\n",
    "        # rearrange columns by category value\n",
    "        df_out.columns = df_out.columns.str.lower()\n",
    "        if code_dict != \"\":\n",
    "            lowerlist = [x.lower() for x in (list(code_dict[definition].values()))]\n",
    "            df_out = df_out[lowerlist]\n",
    "        else:\n",
    "            df_out = df_out.reindex(sorted(df_out.columns), axis=1)\n",
    "        # Null out the diagonal\n",
    "        # np.fill_diagonal(df_out.values, np.nan)\n",
    "        df_out = df_out.where(~df_out.isna(), \"-\")\n",
    "        display(df_out)\n",
    "        df_out.to_csv(f\"output/{output_path}/tables/state_change_{definition}.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_latest_common_comparison(df_clean, definitions, other_vars, output_path,mindate=False):\n",
    "    for definition in definitions:\n",
    "        vars = [s for s in other_vars_combined if s.startswith(definition)]\n",
    "        # display(vars)\n",
    "        if mindate:\n",
    "            df_clean = df_clean[df_clean[f\"{definition}_date\"]==\"1900-01-01\"]\n",
    "            display(\"mindate\")\n",
    "        df_subset = df_clean.loc[~df_clean[definition].isna()]\n",
    "        # display(\"remove na\")\n",
    "        # display(df_subset)\n",
    "        # display(vars)\n",
    "        df_subset=df_subset[[definition]+vars].set_index(definition)\n",
    "        # display(\"remove columns\")\n",
    "        # display(df_subset)\n",
    "        df_subset=df_subset.replace(0,np.nan)\n",
    "        # display(\"replace 0s\")\n",
    "        # display(df_subset)\n",
    "        df_subset2 = df_subset.where(df_subset.eq(df_subset.max(1),axis=0))\n",
    "        # display(\"not sure\")\n",
    "        # display(df_subset2)\n",
    "        df_subset_3 = df_subset2.notnull().astype('int').reset_index()\n",
    "        df_sum = redact_round_table(df_subset_3.groupby(definition).sum())\n",
    "        display(df_sum)\n",
    "        # df_sum.to_csv(f'output/{output_path}/tables/simple_latest_common_{definition}.csv')\n",
    "\n",
    "def simple_state_change(df_clean, definitions, other_vars, output_path):\n",
    "    for definition in definitions:\n",
    "        vars = [s for s in other_vars if s.startswith(definition)]\n",
    "        df_subset = (\n",
    "            df_clean[[definition] + vars]\n",
    "            .replace(0, np.nan)\n",
    "            .set_index(definition)\n",
    "            .reset_index()\n",
    "        )\n",
    "        df_subset[\"n\"] = 1\n",
    "        # Count\n",
    "        df_subset2 = df_subset.loc[~df_subset[definition].isna()]\n",
    "        df_subset3 = redact_round_table(\n",
    "            df_subset2.groupby(definition).count()\n",
    "        ).reset_index()\n",
    "        df_subset3.to_csv(f\"output/{output_path}/tables/simple_state_change_{definition}.csv\")\n",
    "\n",
    "def simple_patient_counts(\n",
    "    df_clean,\n",
    "    definitions,\n",
    "    demographic_covariates,\n",
    "    clinical_covariates,\n",
    "    output_path,\n",
    "    categories=False,\n",
    "):\n",
    "    suffix = \"_filled\"\n",
    "    subgroup = \"with records\"\n",
    "    if categories == True:\n",
    "        li_cat_def = []\n",
    "        li_cat = (\n",
    "            df_clean[definitions[0]]\n",
    "            .dropna()\n",
    "            .astype(str)\n",
    "            .sort_values()\n",
    "            .unique()\n",
    "            .tolist()\n",
    "        )\n",
    "        for x in li_cat:\n",
    "            for definition in definitions:\n",
    "                df_clean.loc[df_clean[definition] == x, f\"{x}_{definition}_filled\"] = 1\n",
    "                li_cat_def.append(f\"{x}_{definition}\")\n",
    "        definitions = li_cat_def\n",
    "\n",
    "    # All with measurement\n",
    "    li_filled = []\n",
    "    for definition in definitions:\n",
    "        df_temp = (\n",
    "            df_clean[[\"patient_id\", definition + suffix]]\n",
    "            .drop_duplicates()\n",
    "            .dropna()\n",
    "            .set_index(\"patient_id\")\n",
    "        )\n",
    "        li_filled.append(df_temp)\n",
    "\n",
    "    df_temp = (\n",
    "        df_clean[[\"patient_id\", \"all_filled\",\"all_missing\"]]\n",
    "        .drop_duplicates()\n",
    "        .dropna()\n",
    "        .set_index(\"patient_id\")\n",
    "    )\n",
    "    li_filled.append(df_temp)\n",
    "\n",
    "    df_temp2 = pd.concat(li_filled, axis=1)\n",
    "    df_temp2[\"population\"] = 1\n",
    "    # Remove list from memory\n",
    "    del li_filled\n",
    "    df_all = pd.DataFrame(df_temp2.sum()).T\n",
    "    df_all[\"group\"], df_all[\"subgroup\"] = [\"all\", subgroup]\n",
    "    df_all = df_all.set_index([\"group\", \"subgroup\"])\n",
    "\n",
    "    # By group\n",
    "    li_group = []\n",
    "    for group in demographic_covariates + clinical_covariates:\n",
    "        li_filled_group = []\n",
    "        for definition in definitions:\n",
    "            df_temp = (\n",
    "                df_clean[[\"patient_id\", definition + suffix, group]]\n",
    "                .drop_duplicates()\n",
    "                .dropna()\n",
    "                .reset_index(drop=True)\n",
    "            )\n",
    "            li_filled_group.append(df_temp)\n",
    "\n",
    "        df_temp = (\n",
    "            df_clean[[\"patient_id\", \"all_filled\",\"all_missing\", group]]\n",
    "            .drop_duplicates()\n",
    "            .dropna()\n",
    "            .reset_index(drop=True)\n",
    "        )\n",
    "        li_filled_group.append(df_temp)\n",
    "\n",
    "        df_reduce = reduce(\n",
    "            lambda df1, df2: pd.merge(df1, df2, on=[\"patient_id\", group], how=\"outer\"),\n",
    "            li_filled_group,\n",
    "        )\n",
    "        df_reduce[\"population\"] = 1\n",
    "        # Remove list from memory\n",
    "        del li_filled_group\n",
    "        df_reduce2 = (\n",
    "            df_reduce.sort_values(by=group)\n",
    "            .drop(columns=[\"patient_id\"])\n",
    "            .groupby(group)\n",
    "            .sum()\n",
    "            .reset_index()\n",
    "        )\n",
    "        df_reduce2[\"group\"] = group\n",
    "        df_reduce2 = df_reduce2.rename(columns={group: \"subgroup\"})\n",
    "        li_group.append(df_reduce2)\n",
    "    df_all_group = pd.concat(li_group, axis=0, ignore_index=True).set_index(\n",
    "        [\"group\", \"subgroup\"]\n",
    "    )\n",
    "    # Remove list from memory\n",
    "    del li_group\n",
    "\n",
    "    # Redact\n",
    "    df_append = redact_round_table(df_all.append(df_all_group))\n",
    "    if categories:\n",
    "        df_append.to_csv(f\"output/{output_path}/tables/simple_patient_counts_categories.csv\")\n",
    "    else:\n",
    "        df_append.to_csv(f\"output/{output_path}/tables/simple_patient_counts.csv\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to function call (Temp/ipykernel_22520/3505910293.py, line 72)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\candrews\\AppData\\Local\\Temp/ipykernel_22520/3505910293.py\"\u001b[1;36m, line \u001b[1;32m72\u001b[0m\n\u001b[1;33m    upset_output_check.loc(comparator_1)= df_clean[comparator_1].fillna(\"Unknown\")\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m cannot assign to function call\n"
     ]
    }
   ],
   "source": [
    "from upsetplot import *\n",
    "import tabulate\n",
    "\n",
    "df_clean = import_clean(\n",
    "        input_path,\n",
    "        definitions,\n",
    "        other_vars_combined,\n",
    "        demographic_covariates,\n",
    "        clinical_covariates,\n",
    "        reg,\n",
    "        null,\n",
    "        date_min,\n",
    "        date_max,\n",
    "        time_delta,\n",
    "        output_path,\n",
    "        code_dict,\n",
    "        dates,\n",
    "        registered,\n",
    "    )\n",
    "\n",
    "from matplotlib import cm\n",
    "# df_clean_c= df_clean.set_index(df_clean.ethnicity_5_filled == 1)\n",
    "# df_clean_c=df_clean_c.set_index(df_clean.ethnicity_new_5_filled == 1, append=True)\n",
    "\n",
    "# df_clean_c[definitions[1]]= df_clean_c[definitions[1]].fillna(\"Unknown\")\n",
    "# display(df_clean_c)\n",
    "# upset = UpSet(df_clean_c,\n",
    "#               intersection_plot_elements=0)\n",
    "\n",
    "# upset.add_stacked_bars(by=definitions[1], colors=cm.Pastel1,\n",
    "#                        title=\"Count by ethnicity\", elements=10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# upset.plot()\n",
    "\n",
    "# # fig = plt.figure(figsize=(10, 3))\n",
    "# # plot(upset, element_size=40)\n",
    "# plt.savefig(\n",
    "#                 f\"output/{output_path}/figures/test.png\"\n",
    "#             )\n",
    "# upset_cat=pd.DataFrame(df_clean[definitions[1]])\n",
    "\n",
    "# for definition in definitions[0:2]:\n",
    "#     for var in other_vars:\n",
    "#         upset_cat[f\"{var}_{definition}\"]=df_clean[definition].str.lower()==var\n",
    "\n",
    "# # upset_cat= upset_cat.set_index(upset_cat[f\"{other_vars[0]}_{definitions[0]}\"] == True)\n",
    "# for definition in definitions[0:2]:\n",
    "#     for var in other_vars:\n",
    "#         display(f\"{var}_{definition}\")\n",
    "#         if (var==other_vars[0] and definition==definitions[0]):\n",
    "#             upset_cat=upset_cat.set_index(upset_cat[f\"{var}_{definition}\"] == True)\n",
    "#         else:    \n",
    "#             upset_cat=upset_cat.set_index(upset_cat[f\"{var}_{definition}\"] == True, append=True)\n",
    "#         upset_cat.drop([f\"{var}_{definition}\"], axis=1, inplace=True)\n",
    "\n",
    "# upset_cat[definitions[1]]= upset_cat[definitions[1]].fillna(\"Unknown\")\n",
    "# upset_cat_plot = UpSet(upset_cat,\n",
    "#               intersection_plot_elements=0)\n",
    "\n",
    "# upset_cat_plot.add_stacked_bars(by=definitions[1], colors=cm.Pastel1,\n",
    "#                        title=\"Count by ethnicity\", elements=10)\n",
    "\n",
    "# upset_cat_plot.plot()\n",
    "\n",
    "\n",
    "def upset(df_clean, output_path, comparator_1, comparator_2):\n",
    "    # create csv for output checking\n",
    "    upset_output_check=df_clean[[comparator_1,comparator_2]]\n",
    "    upset_output_check[comparator_1]= df_clean[comparator_1].fillna(\"Unknown\")\n",
    "    upset_output_check[comparator_2] = df_clean[comparator_2].fillna(\"Unknown\")\n",
    "    upset_output_check=pd.crosstab(upset_output_check[comparator_1], upset_output_check[comparator_2])\n",
    "    display(upset_output_check)\n",
    "    upset_output_check.to_csv(f\"output/{output_path}/figures/upset_output_check.csv\")\n",
    "\n",
    "    upset_df = df_clean.set_index(~df_clean[comparator_1].isnull())\n",
    "    upset_df = upset_df.set_index(~upset_df[comparator_2].isnull(), append=True)\n",
    "\n",
    "    upset_df[comparator_1] = upset_df[comparator_1].fillna(\"Unknown\")\n",
    "    upset = UpSet(upset_df, intersection_plot_elements=0)\n",
    "\n",
    "    upset.add_stacked_bars(\n",
    "        by=comparator_1, colors=cm.Pastel1, title=\"Count by ethnicity\", elements=10\n",
    "    )\n",
    "\n",
    "    upset.plot()\n",
    "    plt.savefig(f\"output/{output_path}/figures/upset_{comparator_1}_{comparator_2}.png\")\n",
    "\n",
    "\n",
    "def upset_cat(df_clean, output_path, comparator_1, comparator_2, other_vars):\n",
    "    upset_cat_df = pd.DataFrame(df_clean[comparator_1])\n",
    "    for definition in [comparator_1, comparator_2]:\n",
    "        for var in other_vars:\n",
    "            upset_cat_df[f\"{var}_{definition}\"] = (\n",
    "                df_clean[definition].str.lower() == var\n",
    "            )\n",
    "    ######################################\n",
    "    for definition in [comparator_1, comparator_2]:\n",
    "        for var in other_vars:\n",
    "            if var == other_vars[0] and definition == comparator_1:\n",
    "                upset_cat_df = upset_cat_df.set_index(\n",
    "                    upset_cat_df[f\"{var}_{definition}\"] == True\n",
    "                )\n",
    "            else:\n",
    "                upset_cat_df = upset_cat_df.set_index(\n",
    "                    upset_cat_df[f\"{var}_{definition}\"] == True, append=True\n",
    "                )\n",
    "            display(upset_cat_df)\n",
    "            upset_cat_df.drop([f\"{var}_{definition}\"], axis=1, inplace=True)\n",
    "    ######################################\n",
    "    display(upset_cat_df)\n",
    "    upset_cat_df[comparator_1] = upset_cat_df[comparator_1].fillna(\"Unknown\")\n",
    "    display(upset_cat_df)\n",
    "    upset_cat = UpSet(upset_cat_df, intersection_plot_elements=0)\n",
    "    upset_cat.add_stacked_bars(\n",
    "        by=comparator_1, colors=cm.Pastel1, title=\"Count by ethnicity\", elements=10\n",
    "    )\n",
    "\n",
    "    upset_cat.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\candrews\\AppData\\Local\\Temp/ipykernel_22520/1673422893.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  upset_output_check[comparator_1]= df_clean[comparator_1].fillna(\"Unknown\")\n",
      "C:\\Users\\candrews\\AppData\\Local\\Temp/ipykernel_22520/1673422893.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  upset_output_check[comparator_2] = df_clean[comparator_2].fillna(\"Unknown\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ethnicity_new_5</th>\n",
       "      <th>Asian</th>\n",
       "      <th>Black</th>\n",
       "      <th>Mixed</th>\n",
       "      <th>Other</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>White</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ethnicity_5</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Asian</th>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mixed</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>35</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unknown</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>52</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "ethnicity_new_5  Asian  Black  Mixed  Other  Unknown  White\n",
       "ethnicity_5                                                \n",
       "Asian               12      4      5     10       32     37\n",
       "Black                6      3     10      3       24     38\n",
       "Mixed                6      6      5      6       38     39\n",
       "Other                5      8      7      6       35     39\n",
       "Unknown             12     12     17     17       52     68\n",
       "White                6      7      5      8       27     35"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 320x384 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "upset(df_clean, output_path, definitions[0],definitions[1])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bd7deed66f04c8f1cb07fbe5b34625baefe8e7d41af3b53c9662fc8ba397df1b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
